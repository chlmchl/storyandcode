<!DOCTYPE html>

<head>
  <link rel="stylesheet" type="text/css" href="../static/style.css" />
</head>
<html>

<body>
  <div id="webcam-container">
    <video id="webcam-video" autoplay="true"></video>
    <canvas id="canvas"></canvas>
  </div>

  <div id="vid-container">
    <video id="video-player2" muted="true" autoplay="true" playsinline="true"></video>
    <video id="video-player" muted="true" autoplay="true" playsinline="true"></video>
  </div>

  <form id="speech-form" enctype="multipart/form-data">
    <label for="text-input">Enter your text input:</label><br>
    <input type="text" id="text-input" name="text-input" required><br>
    <br>
    <input type="submit" value="Submit">
  </form>
  <button id="start_button" role="button" onClick="playIntro()">Enter</button>
  <div class="transcripts">
    <p id="transcript"></p>
    <p id="transcript_11labs">Welcome to the Ayn-Tycho corporation baseline test for off-world training. <br/> Please respond naturally with simple associations to what you hear and see to achieve your baseline and move to the next phase of training. <br/> To initiate say "start"</p>
  </div>

  <script>
    let vids_b1 = []
    let vids_b2 = []
    let vids_b3 = []
    let audio_b1 = []
    let audio_b2 = []
    let audio_b3 = []
    let vids_x = []
    let intro = true;
    let b1 = false;
    let b2 = false; 
    let b3 = false;
    let started = false;
    let b1_index = 0;
    let b2_index = 0;
    let b3_index = 0;

    // Function to set the video source and start playing
    function playVideo(filename, pacing, match) {
      const videoPlayer = document.getElementById('video-player');
      videoPlayer.src = filename;
      // console.log('play video')
      // Wait for the "loadeddata" event before attempting to play
      videoPlayer.addEventListener('loadeddata', () => {
        // console.log('video loaded')
        videoPlayer.play()
          .catch(error => {
            // Play request was interrupted, try again after a short delay
            setTimeout(() => videoPlayer.play(), 50);
          });
      });

      // Attach an event listener to play the next video when the current one ends
      if(!match) {
        setTimeout(() => fetchAndPlayVideo(), pacing);
      } 
    }

    // Function to fetch the video URL and start playing
    function fetchAndPlayVideo() {

        const videoPlayer = document.getElementById('video-player');

        if(intro) {
          console.log("play intro 1");
          videoPlayer.src = "static/vids/batch_x/network_intro_dark_fast.mp4";
          pacing = 20000;
          playVideo(videoPlayer.src, pacing, false);
        } else if(b1 && started) {
          const randomIndex = Math.floor(Math.random() * (vids_b1.length - 1));
          const randomVideoUrl = vids_b1[randomIndex].file_name;
          filename = "static/vids/batch_1/" + randomVideoUrl;
          pacing = 3000;
          playVideo(filename, pacing, false);
        } else if(b2 && started) {
          const randomIndex = Math.floor(Math.random() * (vids_b2.length - 1));
          const randomVideoUrl = vids_b2[randomIndex].file_name;
          filename = "static/vids/batch_2/" + randomVideoUrl;
          pacing = 1500;
          playVideo(filename, pacing, false);
        } else if(b3 && started) {
          const randomIndex = Math.floor(Math.random() * (vids_b3.length - 1));
          const randomVideoUrl = vids_b3[randomIndex].file_name;
          filename = "static/vids/batch_3/" + randomVideoUrl;
          pacing = 1000;
          playVideo(filename, pacing, false);
        }
    }

    // Call the fetchAndPlayVideo function when the page loads
    document.addEventListener('DOMContentLoaded', () => {
      fetchAndPlayVideo();
    });

    // Access the webcam and stream video
    if ('mediaDevices' in navigator && 'getUserMedia' in navigator.mediaDevices) {
      const webcamVideo = document.getElementById('webcam-video');

      // Request access to the webcam
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
          // Display the webcam video stream
          webcamVideo.srcObject = stream;
        })
        .catch(error => {
          // console.log('Unable to access the webcam:', error);
        });
    } else {
      // console.log('Webcam access not supported');
    }

    // Function to play the intro audio
    function playIntro() {
      // Hide the start button
        const startButton = document.getElementById('start_button');
        startButton.style.display = 'none';

        // Show the transcript paragraph
        const transcriptsDiv = document.getElementById('transcript_11labs');
        transcriptsDiv.style.display = 'block';

      // Make a POST request to the "/intro" route
      fetch('/intro', {
        method: 'GET',
      })
      .then(response => response.json())
      .then(data => {
        // Handle the response data, assuming 'data' is an object containing the 'response_text' and 'is_final' fields
        const responseText = data.response_text;
        audioUrl = data.audioUrl;
        csv_array = data.csv_array;
        csv_array_audio = data.csv_array_audio;

        playAudio('static/audio/' + audioUrl);

        for (let i = 1; i < csv_array.length; i++) {
          const [file_name, batch, tags, note] = csv_array[i];

          if (batch === 'b1') {
            vids_b1.push({ file_name, tags });
          } else if (batch === 'b2') {
            vids_b2.push({ file_name, tags });
          } else if (batch === 'b3') {
            vids_b3.push({ file_name, tags });
          }
        }

        for (let i = 1; i < csv_array_audio.length; i++) {
          const [file_name, batch, string, note] = csv_array_audio[i];

          if (batch === 'b1') {
            audio_b1.push({ file_name, string });
          } else if (batch === 'b2') {
            audio_b2.push({ file_name, string });
          } else if (batch === 'b3') {
            audio_b3.push({ file_name, string });
          }
        }
      

      b1 = data.b1;
      // intro = data.intro
    
      document.getElementById('transcript_11labs').innerHTML = responseText;
      })
      .catch(error => {
        // Handle any errors that occurred during the AJAX request
        console.error('Error playing intro:', error);
      });
    }

    function playAudio(audioUrl) {
     //const audioUrl = 'path/to/your/audio.mp3'; // Replace with the actual URL of your audio file

      const audio = new Audio(audioUrl);
      audio.play();
    
      audio.addEventListener('ended', function () {
        // This function will be called when the audio has ended
        startRec();
        if (!started) {
          started = true; 
          b1 = true;
          intro = false
        }
        // Call your desired function here or add your logic.
      });
    }

    function startRec() {
      if ('webkitSpeechRecognition' in window) {
        const recognition = new webkitSpeechRecognition();
        const form = document.getElementById('speech-form');
        const inputField = document.getElementById('text-input');
        let isSpeaking = false;

        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';
        recognition.start();

        recognition.onresult = function (event) {
          const transcript = event.results[event.results.length - 1][0].transcript;
          inputField.value = transcript;
          document.getElementById('transcript').innerHTML = transcript;

          // Check for silence or pauses in speech
          const lastResult = event.results[event.results.length - 1];
          if (lastResult.isFinal) {
            isSpeaking = false;
            if (inputField.value.trim() === 'start') { 
              console.log('started')
              recognition.stop();
              playAudio('static/audio/00_stream1.mp3');
              document.getElementById('transcript_11labs').innerHTML = 'You see a stream';
            }
            if (started) {
              if (inputField.value.trim() !== '') {
                // sendData();
                recognition.stop();
                if(b1){
                  playAudio('static/audio/' + audio_b1[b1_index].file_name);
                  document.getElementById('transcript_11labs').innerHTML = audio_b1[b1_index].string;
                  b1_index += 1;
                  if( b1_index >= audio_b1.length) {
                    b1 = false;
                    b2 = true;
                  }
                } else if (b2) {
                  playAudio('static/audio/' + audio_b2[b2_index].file_name);
                  document.getElementById('transcript_11labs').innerHTML = audio_b2[b2_index].string;
                  b2_index += 1;
                  if( b2_index >= audio_b2.length) {
                    b2 = false;
                    b3 = true;
                  }
                } else if (b3) {
                  playAudio('static/audio/' + audio_b3[b3_index].file_name);
                  document.getElementById('transcript_11labs').innerHTML = audio_b3[b3_index].string;
                  b3_index += 1;
                  if( b3_index >= audio_b3.length) {
                    b3 = false;
                  }
                }
              }
            }
          } else {
            isSpeaking = true;
          }
        };

        recognition.onstart = function () {
          isSpeaking = true;
        };

        recognition.onend = function () {
          if (isSpeaking) {
            // The user has stopped speaking
            isSpeaking = false;
            // Wait for 1 second before restarting the recognition

          }
        };

        function sendData() {
          const formData = new FormData(form);
          fetch('/generate', {
            method: 'POST',
            body: formData,
          })
            .then(response => response.json()) // Parse the response as JSON
            .then(data => {
              // Handle the response data, assuming 'data' is an object containing the 'response_text' and 'is_final' fields
              const responseText = data.response_text;
              b1 = data.b1;
              b2 = data.b2;
              b3 = data.b3;

              // console.log('Is b1? :', b1);
              // console.log('Is b2? :', b2);
              // console.log('Is b3? :', b3);
              // Log the received response text in the console
              // console.log('Received response text:', responseText);

              document.getElementById('transcript_11labs').innerHTML = responseText;
              const matchingFiles = getMatchingFileName(responseText, vids_b1);
              file = matchingFiles[Math.random(0, matchingFiles.length() - 1)]
              console.log(file)
              fetchAndPlayVideo(file, 2000, true);
              // Check if the response is final and act accordingly
              if (data.is_final) {
                // Do something when the response is final, such as ending the recognition or resetting the form
                recognition.stop();
              }

              // Restart the recognition after the generated audio has finished streaming
              setTimeout(() => {
                recognition.start();
              }, 800);
            })
            .catch(error => {
              // Handle any errors that occurred during the AJAX request
              console.error('Error sending form data:', error);

              // Restart the recognition after an error occurs
              setTimeout(() => {
                recognition.start();
              }, 1000);
            });
        }

        form.addEventListener('submit', function (event) {
          event.preventDefault();
          // Stop the recognition when the form is manually submitted
          recognition.stop();
          // Call the sendData function only when the user speaks (not generated audio)
          if (inputField.value.trim() !== '') {
            sendData();
          }
        });

        // console.log("isSpeaking: " + isSpeaking)
      }
    }

    function getMatchingFileName(response, vidsArray) {
      const matchingFiles = [];
      const wordsInResponse = response.toLowerCase().match(/\b\w+\b/g) || []; // Extract words from response
      // console.log(wordsInResponse);

      for (const item of vidsArray) {
        const tags = item.tags.toLowerCase().split(', '); // Convert tags to lowercase and split by comma
        const fileName = item.file_name;

        for (const word of wordsInResponse) {
          if (tags.includes(word)) {
            // console.log('Found matching word : ' + word);
            matchingFiles.push(fileName);
            break; // Break out of the inner loop once a match is found
          }
        }
      }
      
      // console.log('matching files : ' + matchingFiles)
      return matchingFiles;
    }

  </script>
</body>

</html>